{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras.callbacks import TensorBoard, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1b37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    'data_path': '../data/',\n",
    "    'model_path': '../model/',\n",
    "    'model_name': 'recursive_prediction',\n",
    "    'model_type': 'cnn1d',\n",
    "    \n",
    "    'dtype': tf.float32,\n",
    "    \n",
    "    'valid_start_date_time': '2020-08-11 00',\n",
    "    'test_start_date_time': '2020-08-18 00',\n",
    "    \n",
    "    'buffer_size': 512,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-4,\n",
    "    'epochs': 100,\n",
    "    'es_patience': 10,\n",
    "    \n",
    "    'window_size': 7*24,\n",
    "    'shift': 1,\n",
    "    'target_length': 3,\n",
    "}\n",
    "\n",
    "CONFIGS['tensorboard_log_path'] = f'../logs/tensorboard/{CONFIGS[\"model_name\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef52c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin = pd.read_csv(CONFIGS['data_path']+'train.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f002b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape: (122400, 10)\n"
     ]
    }
   ],
   "source": [
    "data = deepcopy(train_origin)\n",
    "\n",
    "data.columns = [\n",
    "    'num', 'date_time', 'target', 'temp', 'wind',\n",
    "    'humid', 'rain', 'sun', 'non_elec_eq', 'sunlight_eq'\n",
    "]\n",
    "\n",
    "data['num'] -= 1\n",
    "\n",
    "print(f'data.shape: {data.shape}')\n",
    "\n",
    "CONFIGS['last_date_time'] = data['date_time'].max()\n",
    "CONFIGS['n_buildings'] = len(data['num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42502fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_time_data(data):\n",
    "    \n",
    "    new_data = data.copy()\n",
    "\n",
    "    new_data['date_time'] = data['date_time'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H'))\n",
    "    \n",
    "    new_data['time_stamp'] = new_data['date_time'].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    new_data['year'] = new_data['date_time'].apply(lambda x: x.year)\n",
    "    new_data['month'] = new_data['date_time'].apply(lambda x: x.month)\n",
    "    new_data['day'] = new_data['date_time'].apply(lambda x: x.day)\n",
    "    \n",
    "    new_data['hour'] = new_data['date_time'].apply(lambda x: x.hour)\n",
    "    new_data['cos_hour'] = np.cos(2*np.pi*(new_data['hour']/24))\n",
    "    new_data['sin_hour'] = np.sin(2*np.pi*(new_data['hour']/24))\n",
    "\n",
    "    new_data['weekday'] = new_data['date_time'].apply(lambda x: x.weekday())\n",
    "    new_data['cos_weekday'] = np.cos(2*np.pi*(new_data['weekday']/7))\n",
    "    new_data['sin_weekday'] = np.sin(2*np.pi*(new_data['weekday']/7))\n",
    "    \n",
    "    new_data['is_holiday'] = 0\n",
    "    new_data.loc[(new_data['weekday'] == 5) | (new_data['weekday'] == 6), 'is_holiday'] = 1\n",
    "    new_data.loc[(new_data['month'] == 8) & (new_data['day'] == 17), 'is_holiday'] = 1\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf4e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = mk_time_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fdc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_building_info(data, data_for_calc, CONFIGS):\n",
    "        \n",
    "    new_data = data.copy()\n",
    "    new_data['range'] = 0\n",
    "    new_data['mean'] = 0\n",
    "    new_data['std'] = 0\n",
    "    new_data['holiday_gap'] = 0\n",
    "    new_data['day_gap'] = 0\n",
    "\n",
    "    for num in range(CONFIGS['n_buildings']):\n",
    "        building = data_for_calc.query(f'num == {num}')\n",
    "        \n",
    "        bt_range = building['target'].max()-building['target'].min()\n",
    "        bt_mean = building['target'].mean()\n",
    "        bt_std = building['target'].std()\n",
    "        bt_holiday_gap = abs(building.query('is_holiday == 0')['target'].mean() - building.query('is_holiday == 1')['target'].mean())\n",
    "        bt_day_gap = 0\n",
    "        for d in range(building.shape[0]//24):\n",
    "            tmp = building['target'][d*24:(d+1)*24]\n",
    "            bt_day_gap += (tmp.max()-tmp.min())/(building.shape[0]//24)\n",
    "            \n",
    "        new_data.loc[new_data['num']==num, 'range'] = bt_range\n",
    "        new_data.loc[new_data['num']==num, 'mean'] = bt_mean\n",
    "        new_data.loc[new_data['num']==num, 'std'] = bt_std\n",
    "        new_data.loc[new_data['num']==num, 'holiday_gap'] = bt_holiday_gap\n",
    "        new_data.loc[new_data['num']==num, 'day_gap'] = bt_day_gap\n",
    "        \n",
    "    new_data['mean_to_inverse'] = new_data['mean']\n",
    "    new_data['std_to_inverse'] = new_data['std']\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebaea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = mk_building_info(\n",
    "    new_data,\n",
    "    new_data[new_data['date_time']<CONFIGS['valid_start_date_time']],\n",
    "    CONFIGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8655ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_mean_std_dict(data, scaling_by_building_cols):\n",
    "    mean_std_dict = {}\n",
    "    for num in range(60):\n",
    "        building = data.query(f'num == {num}')\n",
    "        mean_std_dict[num] = {\n",
    "            col: {\n",
    "                'mean': building[col].mean(),\n",
    "                'std': building[col].std()\n",
    "            } for col in scaling_by_building_cols\n",
    "        }\n",
    "    return mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01506353",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_by_building_cols = [\n",
    "    'temp', 'wind', 'humid', 'rain', 'sun', 'time_stamp', 'target',\n",
    "]\n",
    "scaling_by_all_cols = ['range', 'mean', 'std', 'holiday_gap', 'day_gap']\n",
    "\n",
    "mean_std_dict = mk_mean_std_dict(\n",
    "    new_data[new_data['date_time'] < CONFIGS['valid_start_date_time']],\n",
    "    scaling_by_building_cols\n",
    ")\n",
    "CONFIGS['mean_std_dict'] = mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d134a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(data, scaling_by_building_cols, scaling_by_all_cols, mean_std_dict=None):\n",
    "    if not mean_std_dict:\n",
    "        mean_std_dict = mk_mean_std_dict(data, scaling_by_building_cols)\n",
    "        \n",
    "    new_data = data.copy()\n",
    "    for num in range(60):\n",
    "        for col in scaling_by_building_cols:\n",
    "            new_data.loc[new_data['num']==num, col] -= mean_std_dict[num][col]['mean']\n",
    "            new_data.loc[new_data['num']==num, col] /= mean_std_dict[num][col]['std']\n",
    "    \n",
    "    for col in scaling_by_all_cols:\n",
    "        m = new_data.loc[:, col].mean()\n",
    "        s = new_data.loc[:, col].std()\n",
    "        new_data.loc[:, col] -= m\n",
    "        new_data.loc[:, col] /= s\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6674807",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = standard_scaling(new_data, scaling_by_building_cols, scaling_by_all_cols, mean_std_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b337cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_num_cols = ['num']\n",
    "building_info_cols = [\n",
    "    'range', 'mean', 'std', 'holiday_gap', 'day_gap',\n",
    "    'non_elec_eq', 'sunlight_eq',\n",
    "]\n",
    "target_time_info_cols = [\n",
    "    'temp', 'wind', 'humid', 'rain', 'sun', 'time_stamp',\n",
    "    'cos_hour', 'sin_hour', 'cos_weekday', 'sin_weekday',\n",
    "    'is_holiday',\n",
    "]\n",
    "time_series_cols = [\n",
    "    'temp', 'wind', 'humid', 'rain', 'sun', 'time_stamp',\n",
    "    'cos_hour', 'sin_hour', 'cos_weekday', 'sin_weekday',\n",
    "    'is_holiday', 'target',\n",
    "]\n",
    "target_cols = ['target']\n",
    "to_inverse_cols = ['mean_to_inverse', 'std_to_inverse']\n",
    "input_cols = list(set(\n",
    "    building_num_cols + building_info_cols + target_time_info_cols +\n",
    "    time_series_cols + target_cols + to_inverse_cols\n",
    "))\n",
    "\n",
    "CONFIGS['building_num_cols'] = building_num_cols\n",
    "CONFIGS['building_info_cols'] = building_info_cols\n",
    "CONFIGS['target_time_info_cols'] = target_time_info_cols\n",
    "CONFIGS['time_series_cols'] = time_series_cols\n",
    "CONFIGS['target_cols'] = target_cols\n",
    "CONFIGS['to_inverse_cols'] = to_inverse_cols\n",
    "CONFIGS['input_cols'] = input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda65897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_time_series(data, CONFIGS, is_input=False, is_time_series=False):\n",
    "    if is_input:\n",
    "        data = data[:-CONFIGS['target_length']*CONFIGS['n_buildings']]\n",
    "    else:\n",
    "        data = data[CONFIGS['window_size']*CONFIGS['n_buildings']:]\n",
    "    ds = Dataset.from_tensor_slices(data)\n",
    "    if is_time_series:\n",
    "        if is_input:\n",
    "            size = CONFIGS['window_size']\n",
    "        else:\n",
    "            size = CONFIGS['target_length']\n",
    "        ds = ds.window(\n",
    "            size=size, shift=CONFIGS['shift'],\n",
    "            stride=CONFIGS['n_buildings'], drop_remainder=True\n",
    "        )\n",
    "        ds = ds.flat_map(lambda x: x).batch(size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def mk_dataset(data, CONFIGS, batch_size=None, shuffle=False):\n",
    "    \n",
    "    if not batch_size:\n",
    "        batch_size = CONFIGS['batch_size']\n",
    "    \n",
    "    data = data.sort_values(['date_time', 'num'])\n",
    "\n",
    "    building_num = data[CONFIGS['building_num_cols']]\n",
    "    building_info = data[CONFIGS['building_info_cols']]\n",
    "    target_time_info = data[CONFIGS['target_time_info_cols']]\n",
    "    time_series = data[CONFIGS['time_series_cols']]\n",
    "    to_inverse = data[CONFIGS['to_inverse_cols']]\n",
    "    target = data[CONFIGS['target_cols']]\n",
    "\n",
    "    building_num_ds = mk_time_series(building_num, CONFIGS)\n",
    "    building_info_ds = mk_time_series(building_info, CONFIGS)\n",
    "    target_time_info_ds = mk_time_series(target_time_info, CONFIGS)\n",
    "    time_series_ds = mk_time_series(time_series, CONFIGS, is_input=True, is_time_series=True)\n",
    "    to_inverse_ds = mk_time_series(to_inverse, CONFIGS)\n",
    "    target_ds = mk_time_series(target, CONFIGS, is_time_series=True)\n",
    "\n",
    "    ds = Dataset.zip((\n",
    "        (\n",
    "            building_num_ds,\n",
    "            building_info_ds,\n",
    "            target_time_info_ds,\n",
    "            time_series_ds,\n",
    "            to_inverse_ds\n",
    "        ),\n",
    "        target_ds\n",
    "    ))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(CONFIGS['buffer_size'])\n",
    "    ds = ds.batch(batch_size).prefetch(2)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0107708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 08:39:47.363075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.368819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.369342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.370096: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-18 08:39:47.370680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.371196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.371679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.697121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.697497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.697825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-18 08:39:47.698145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6358 MB memory:  -> device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "str_to_dt = lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H')\n",
    "hour_to_td = lambda x: datetime.timedelta(hours=x)\n",
    "\n",
    "train = new_data.loc[\n",
    "    new_data['date_time'] < \\\n",
    "        str_to_dt(CONFIGS['valid_start_date_time']),\n",
    "    :\n",
    "]\n",
    "valid = new_data.loc[\n",
    "    (new_data['date_time'] >= \\\n",
    "        str_to_dt(CONFIGS['valid_start_date_time'])-hour_to_td(CONFIGS['window_size']))&\\\n",
    "    (new_data['date_time'] < \\\n",
    "         str_to_dt(CONFIGS['test_start_date_time'])),\n",
    "    :\n",
    "]\n",
    "test = new_data.loc[\n",
    "    new_data['date_time'] >= \\\n",
    "        str_to_dt(CONFIGS['test_start_date_time'])-hour_to_td(CONFIGS['window_size']),\n",
    "    :\n",
    "]\n",
    "\n",
    "train_ds = mk_dataset(train, CONFIGS, shuffle=True)\n",
    "valid_ds = mk_dataset(valid, CONFIGS, batch_size=CONFIGS['n_buildings'])\n",
    "test_ds = mk_dataset(test, CONFIGS, batch_size=CONFIGS['n_buildings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71c8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSE(Loss):\n",
    "    \n",
    "    def __init__(self, target_max, name=\"custom_mse\"):\n",
    "        super(CustomMSE, self).__init__(name=name)\n",
    "        self.target_max = target_max\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.squeeze(y_true)\n",
    "        mean = tf.reshape(y_pred[:, -2], (-1, 1))\n",
    "        std = tf.reshape(y_pred[:, -1], (-1, 1))\n",
    "        y_pred = y_pred[:, :-2]\n",
    "\n",
    "        y_true_inversed = y_true*std+mean\n",
    "        y_pred_inversed = y_pred*std+mean\n",
    "        \n",
    "        y_true_inversed_scaled = y_true_inversed/self.target_max\n",
    "        y_pred_inversed_scaled = y_pred_inversed/self.target_max\n",
    "\n",
    "        mse = tf.reduce_mean((y_true_inversed_scaled-y_pred_inversed_scaled)**2)\n",
    "        return mse\n",
    "\n",
    "    \n",
    "class InversedRMSE(Metric):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name=\"inversed_rmse\", **kwargs):\n",
    "        super(InversedRMSE, self).__init__(name=name, **kwargs)\n",
    "        self.inversed_mse = self.add_weight(name='inversed_mse', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "        self.CONFIGS = CONFIGS\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, (-1, CONFIGS['target_length']))\n",
    "        mean = tf.reshape(y_pred[:, -2], (-1, 1))\n",
    "        std = tf.reshape(y_pred[:, -1], (-1, 1))\n",
    "        y_pred = y_pred[:, :-2]\n",
    "\n",
    "        y_true_inversed = y_true*std+mean\n",
    "        y_pred_inversed = y_pred*std+mean\n",
    "\n",
    "        error = tf.reduce_sum(tf.math.squared_difference(y_true_inversed, y_pred_inversed))\n",
    "        \n",
    "        self.inversed_mse.assign_add(error)\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), CONFIGS['dtype']))\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(tf.math.divide_no_nan(self.inversed_mse, self.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a38be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingNum(Layer):\n",
    "\n",
    "    def __init__(self, CONFIGS, name='building_num_layer', **kwargs):\n",
    "        super(BuildingNum, self).__init__(name=name, **kwargs)\n",
    "        self.building_num_emb = Embedding(\n",
    "            input_dim=CONFIGS['n_buildings'],\n",
    "            output_dim=CONFIGS['embedding_dim']\n",
    "        )\n",
    "        self.bn_outputs = Reshape(target_shape=(CONFIGS['embedding_dim'],))\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(BuildingNum, self).get_config().copy()\n",
    "        config.update({\n",
    "            'building_num_emb': self.building_num_emb,\n",
    "            'bn_outputs': self.bn_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.building_num_emb(inputs)\n",
    "        outputs = self.bn_outputs(x)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class BuildingInfo(Layer):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name='building_info_layer', **kwargs):\n",
    "        super(BuildingInfo, self).__init__(name=name, **kwargs)\n",
    "        self.bi_dense_0 = Dense(16, activation='relu')\n",
    "        self.dropout_0 = Dropout(0.3)\n",
    "        self.bi_outputs = Dense(32, activation='relu')\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(BuildingInfo, self).get_config().copy()\n",
    "        config.update({\n",
    "            'bi_dense_0': self.bi_dense_0,\n",
    "            'dropout_0': self.dropout_0,\n",
    "            'bi_outputs': self.bi_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.bi_dense_0(inputs)\n",
    "        x = self.dropout_0(x)\n",
    "        outputs = self.bi_outputs(x)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class TargetTimeInfo(Layer):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name='target_time_info_layer', **kwargs):\n",
    "        super(TargetTimeInfo, self).__init__(name=name, **kwargs)\n",
    "        self.tti_dense_0 = Dense(16, activation='relu')\n",
    "        self.dropout_0 = Dropout(0.3)\n",
    "        self.tti_outputs = Dense(32, activation='relu')\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(TargetTimeInfo, self).get_config().copy()\n",
    "        config.update({\n",
    "            'tti_dense_0': self.tti_dense_0,\n",
    "            'dropout_0': self.dropout_0,\n",
    "            'tti_outputs': self.tti_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.tti_dense_0(inputs)\n",
    "        x = self.dropout_0(x)\n",
    "        outputs = self.tti_outputs(x)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class TimeSeries(Layer):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name='time_series_layer', **kwargs):\n",
    "        super(TimeSeries, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        if CONFIGS['model_type'] == 'flatten':\n",
    "            pass\n",
    "        elif CONFIGS['model_type'] == 'cnn1d':\n",
    "            self.conv1d_0 = Conv1D(16, 3, 2, activation='relu')\n",
    "            self.pool1d_0 = MaxPool1D(2)\n",
    "            self.conv1d_1 = Conv1D(32, 3, 2, activation='relu')\n",
    "            self.pool1d_1 = MaxPool1D(2)\n",
    "        elif CONFIGS['model_type'] == 'cnn2d':\n",
    "            self.conv2d_reshape = Reshape(target_shape=(\n",
    "                CONFIGS['window_size'], len(CONFIGS['time_series_cols']), 1\n",
    "            ))\n",
    "            self.conv2d_0 = Conv2D(8, (3, 1), strides=(2, 1), activation='relu')\n",
    "            self.pool2d_0 = MaxPool2D((2, 1))\n",
    "            self.conv2d_1 = Conv2D(16, (3, 1), strides=(2, 1), activation='relu')\n",
    "            self.pool2d_1 = MaxPool2D((2, 1))\n",
    "        elif CONFIGS['model_type'] == 'lstm':\n",
    "            self.lstm_0 = LSTM(16, return_sequences=True, activation='relu')\n",
    "            self.lstm_1 = LSTM(32, activation='relu')\n",
    "        elif CONFIGS['model_type'] == 'bilstm':\n",
    "            self.bilstm_0 = Bidirectional(LSTM(16, return_sequences=True, activation='relu'))\n",
    "            self.bilstm_1 = Bidirectional(LSTM(32, activation='relu'))\n",
    "        self.time_series_outputs = Flatten()\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(TimeSeries, self).get_config().copy()\n",
    "        if CONFIGS['model_type'] == 'flatten':\n",
    "            pass\n",
    "        elif CONFIGS['model_type'] == 'cnn1d':\n",
    "            config.update({\n",
    "                'conv1d_0': self.conv1d_0,\n",
    "                'pool1d_0': self.pool1d_0,\n",
    "                'conv1d_1': self.conv1d_1,\n",
    "                'pool1d_1': self.pool1d_1,\n",
    "            })\n",
    "        elif CONFIGS['model_type'] == 'cnn2d':\n",
    "            config.update({\n",
    "                'conv2d_reshape': self.conv2d_reshape,\n",
    "                'conv2d_0': self.conv2d_0,\n",
    "                'pool2d_0': self.pool2d_0,\n",
    "                'conv2d_1': self.conv2d_1,\n",
    "                'pool2d_1': self.pool2d_1,\n",
    "            })\n",
    "        elif CONFIGS['model_type'] == 'lstm':\n",
    "            config.update({\n",
    "                'lstm_0': self.lstm_0,\n",
    "                'lstm_1': self.lstm_1,\n",
    "            })\n",
    "        elif CONFIGS['model_type'] == 'bilstm':\n",
    "            config.update({\n",
    "                'bilstm_0': self.bilstm_0,\n",
    "                'bilstm_1': self.bilstm_1,\n",
    "            })\n",
    "        config.update({\n",
    "            'time_series_outputs': self.time_series_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if CONFIGS['model_type'] == 'flatten':\n",
    "            x = inputs\n",
    "        elif CONFIGS['model_type'] == 'cnn1d':\n",
    "            x = self.conv1d_0(inputs)\n",
    "            x = self.pool1d_0(x)\n",
    "            x = self.conv1d_1(x)\n",
    "            x = self.pool1d_1(x)\n",
    "        elif CONFIGS['model_type'] == 'cnn2d':\n",
    "            x = self.conv2d_reshape(x)\n",
    "            x = self.conv2d_0(x)\n",
    "            x = self.pool2d_0(x)\n",
    "            x = self.conv2d_1(x)\n",
    "            x = self.pool2d_1(x)\n",
    "        elif CONFIGS['model_type'] == 'lstm':\n",
    "            x = self.lstm_0(x)\n",
    "            x = self.lstm_1(x)\n",
    "        elif CONFIGS['model_type'] == 'bilstm':\n",
    "            x = self.bilstm_0(x)\n",
    "            x = self.bilstm_1(x)\n",
    "        outputs = self.time_series_outputs(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0db0bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_model(CONFIGS, model_name=None, print_summary=False):\n",
    "    \n",
    "    # building_num\n",
    "    building_num_inputs = Input(batch_shape=(None, 1), name='building_num_inputs')\n",
    "    bn_outputs = BuildingNum(CONFIGS)(building_num_inputs)\n",
    "    \n",
    "    # building_info\n",
    "    building_info_inputs = Input(\n",
    "        batch_shape=(None, len(CONFIGS['building_info_cols'])),\n",
    "        name='building_info_inputs'\n",
    "    )\n",
    "    bi_outputs = BuildingInfo(CONFIGS)(building_info_inputs)\n",
    "    \n",
    "    # target_time_info\n",
    "    target_time_info_inputs = Input(\n",
    "        batch_shape=(None, len(CONFIGS['target_time_info_cols'])),\n",
    "        name='target_time_info_inputs'\n",
    "    )\n",
    "    tti_outputs = TargetTimeInfo(CONFIGS)(target_time_info_inputs)\n",
    "    \n",
    "    # time_series\n",
    "    time_series_inputs = Input(batch_shape=(\n",
    "        None, CONFIGS['window_size'], len(CONFIGS['time_series_cols'])\n",
    "    ), name='time_series_inputs')\n",
    "    time_series_outputs = TimeSeries(CONFIGS)(time_series_inputs)\n",
    "    \n",
    "    concat = Concatenate(name='concat')([bn_outputs, bi_outputs, tti_outputs, time_series_outputs])\n",
    "        \n",
    "    dense_0 = Dense(64, activation='relu', name='dense_0')(concat)\n",
    "    dropout_0 = Dropout(0.3, name='dropout_0')(dense_0)\n",
    "    dense_1 = Dense(32, activation='relu', name='dense_1')(dropout_0)\n",
    "    dropout_1 = Dropout(0.3, name='dropout_1')(dense_1)\n",
    "    outputs = Dense(CONFIGS['target_length'], name='outputs')(dropout_1)\n",
    "    \n",
    "    # to_inverse\n",
    "    to_inverse_inputs = Input(batch_shape=(None, len(CONFIGS['to_inverse_cols'])), name='to_inverse_inputs')\n",
    "    concat_to_inverse = Concatenate(name='concat_to_inverse')([outputs, to_inverse_inputs])\n",
    "    \n",
    "    if not model_name:\n",
    "        model_name = CONFIGS['model_name']\n",
    "    \n",
    "    model = Model(\n",
    "        inputs = [\n",
    "            building_num_inputs,\n",
    "            building_info_inputs,\n",
    "            target_time_info_inputs,\n",
    "            time_series_inputs,\n",
    "            to_inverse_inputs\n",
    "        ],\n",
    "        outputs = concat_to_inverse,\n",
    "        name = model_name\n",
    "    )\n",
    "    \n",
    "    custom_mse = CustomMSE(CONFIGS['target_max'])\n",
    "    inversed_rmse = InversedRMSE(CONFIGS)\n",
    "    optimizer = Adam(learning_rate=CONFIGS['learning_rate'])\n",
    "    model.compile(\n",
    "        loss = custom_mse,\n",
    "        optimizer = optimizer,\n",
    "        metrics = [inversed_rmse],\n",
    "    )\n",
    "    \n",
    "    if print_summary:\n",
    "        model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace97d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"recursive_prediction\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " building_num_inputs (InputLaye  [(None, 1)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " building_info_inputs (InputLay  [(None, 7)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " target_time_info_inputs (Input  [(None, 11)]        0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " time_series_inputs (InputLayer  [(None, 168, 12)]   0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " building_num_layer (BuildingNu  (None, 10)          600         ['building_num_inputs[0][0]']    \n",
      " m)                                                                                               \n",
      "                                                                                                  \n",
      " building_info_layer (BuildingI  (None, 32)          672         ['building_info_inputs[0][0]']   \n",
      " nfo)                                                                                             \n",
      "                                                                                                  \n",
      " target_time_info_layer (Target  (None, 32)          736         ['target_time_info_inputs[0][0]']\n",
      " TimeInfo)                                                                                        \n",
      "                                                                                                  \n",
      " time_series_layer (TimeSeries)  (None, 320)         2160        ['time_series_inputs[0][0]']     \n",
      "                                                                                                  \n",
      " concat (Concatenate)           (None, 394)          0           ['building_num_layer[0][0]',     \n",
      "                                                                  'building_info_layer[0][0]',    \n",
      "                                                                  'target_time_info_layer[0][0]', \n",
      "                                                                  'time_series_layer[0][0]']      \n",
      "                                                                                                  \n",
      " dense_0 (Dense)                (None, 64)           25280       ['concat[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_0 (Dropout)            (None, 64)           0           ['dense_0[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           2080        ['dropout_0[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, 3)            99          ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " to_inverse_inputs (InputLayer)  [(None, 2)]         0           []                               \n",
      "                                                                                                  \n",
      " concat_to_inverse (Concatenate  (None, 5)           0           ['outputs[0][0]',                \n",
      " )                                                                'to_inverse_inputs[0][0]']      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,627\n",
      "Trainable params: 31,627\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CONFIGS['target_max'] = \\\n",
    "    data[data['date_time']<CONFIGS['valid_start_date_time']]['target'].max()\n",
    "CONFIGS['embedding_dim'] = 10\n",
    "\n",
    "model = set_model(CONFIGS, print_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53151e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_eval(model, ds, data_usage, CONFIGS):\n",
    "    \n",
    "    if data_usage == 'valid':\n",
    "        seq_len = str_to_dt(CONFIGS['test_start_date_time']) - \\\n",
    "            str_to_dt(CONFIGS['valid_start_date_time'])\n",
    "    elif data_usage == 'test':\n",
    "        seq_len = str_to_dt(CONFIGS['last_date_time'])+datetime.timedelta(hours=1) - \\\n",
    "            str_to_dt(CONFIGS['test_start_date_time'])\n",
    "    seq_len = seq_len.total_seconds()/3600\n",
    "\n",
    "    (_, _, _, fisrt_ts, _), _ = iter(ds).next()\n",
    "    ts_target = fisrt_ts[..., -1:]\n",
    "\n",
    "    inversed_mse = 0\n",
    "    for i, ((bn, bi, tti, ts, ti), y_true) in enumerate(ds):\n",
    "        assert len(y_true) == CONFIGS['n_buildings'], \\\n",
    "            f'batch_size is {len(y_true)} now. Set batch_size same as CONFIGS[\"n_buildings\"]'\n",
    "        assert seq_len % CONFIGS['target_length'] == 0, \\\n",
    "            f'seq_len must be multiple of target_length. Now seq_len: {seq_len}, target_length: {CONFIGS[\"target_length\"]}'\n",
    "        if i%CONFIGS['target_length'] != 0:\n",
    "            continue\n",
    "        ts_wo_target = ts[..., :-1]\n",
    "        ts_concat = tf.concat([ts_wo_target, ts_target], axis=-1)\n",
    "\n",
    "        y_true = tf.reshape(y_true, (CONFIGS['n_buildings'], CONFIGS['target_length']))\n",
    "        y_pred = model.predict((bn, bi, tti, ts_concat, ti))\n",
    "        y_pred, mean, std = y_pred[..., :-2], y_pred[..., [-2]], y_pred[..., [-1]]\n",
    "\n",
    "        ts_target = tf.concat([\n",
    "            ts_target[:, CONFIGS['target_length']:, :],\n",
    "            y_pred.reshape(CONFIGS['n_buildings'], CONFIGS['target_length'], 1)\n",
    "        ], axis=1)\n",
    "\n",
    "        y_true_inversed = y_true*std+mean\n",
    "        y_pred_inversed = y_pred*std+mean\n",
    "\n",
    "        inversed_mse += tf.reduce_sum((y_true_inversed-y_pred_inversed)**2)/(seq_len*CONFIGS['n_buildings'])\n",
    "\n",
    "    inversed_rmse = inversed_mse**0.5\n",
    "\n",
    "    return inversed_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f57d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestByRecursiveRMSE(Callback):\n",
    "\n",
    "    def __init__(self, valid_ds, CONFIGS):\n",
    "        super(BestByRecursiveRMSE, self).__init__()\n",
    "        self.valid_ds = valid_ds\n",
    "        self.CONFIGS = CONFIGS\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.best_epoch = None\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch = 0\n",
    "        self.best_train_loss = np.inf\n",
    "        self.best_valid_rmse = np.inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.best_epoch = epoch\n",
    "        train_loss = logs.get('loss')\n",
    "        train_inversed_rmse = logs.get('inversed_rmse')\n",
    "        valid_rmse = recursive_eval(self.model, self.valid_ds, 'valid', self.CONFIGS)\n",
    "        print(f'Epoch: {epoch}')\n",
    "        print(f'\\ttrain loss: {train_loss:.07f}\\ttrain_inversed_rmse: {train_inversed_rmse:.07f}')\n",
    "        print(f'\\trecursive valid rmse: {valid_rmse:.07f}\\n')\n",
    "        \n",
    "        if np.less(valid_rmse, self.best_valid_rmse):\n",
    "            self.best_train_loss = train_loss\n",
    "            self.best_train_inversed_rmse = train_inversed_rmse\n",
    "            self.best_valid_rmse = valid_rmse\n",
    "            self.wait = 0\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= CONFIGS['es_patience']:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            self.model.save_weights(f'{CONFIGS[\"model_path\"]}{CONFIGS[\"model_name\"]}.h5')\n",
    "            print(f'\\nBest epoch by recursive valid rmse: {self.best_epoch}')\n",
    "            print(f'\\ttrain loss: {self.best_train_loss:.07f}\\ttrain_inversed_rmse: {self.best_train_inversed_rmse:.07f}')\n",
    "            print(f'\\trecursive valid rmse: {self.best_valid_rmse:.07f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a889564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_ds, valid_ds, CONFIGS):\n",
    "    \n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir = CONFIGS['tensorboard_log_path']\n",
    "    )\n",
    "    best_by_recursive_rmse = BestByRecursiveRMSE(valid_ds, CONFIGS)\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        batch_size = CONFIGS['batch_size'],\n",
    "        epochs = CONFIGS['epochs'],\n",
    "        callbacks = [\n",
    "            best_by_recursive_rmse,\n",
    "            tensorboard_callback,\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdb115f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 08:39:49.829832: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "\ttrain loss: 0.0023470\ttrain_inversed_rmse: 819.2539062\n",
      "\trecursive valid rmse: 696.1470839\n",
      "\n",
      "Epoch: 1\n",
      "\ttrain loss: 0.0013332\ttrain_inversed_rmse: 617.4653931\n",
      "\trecursive valid rmse: 612.2616672\n",
      "\n",
      "Epoch: 2\n",
      "\ttrain loss: 0.0010563\ttrain_inversed_rmse: 549.6088867\n",
      "\trecursive valid rmse: 564.6299684\n",
      "\n",
      "Epoch: 3\n",
      "\ttrain loss: 0.0008432\ttrain_inversed_rmse: 491.0686340\n",
      "\trecursive valid rmse: 519.7577684\n",
      "\n",
      "Epoch: 4\n",
      "\ttrain loss: 0.0007395\ttrain_inversed_rmse: 459.8553772\n",
      "\trecursive valid rmse: 499.0166944\n",
      "\n",
      "Epoch: 5\n",
      "\ttrain loss: 0.0006378\ttrain_inversed_rmse: 427.0700989\n",
      "\trecursive valid rmse: 485.2085708\n",
      "\n",
      "Epoch: 6\n",
      "\ttrain loss: 0.0005815\ttrain_inversed_rmse: 407.7862854\n",
      "\trecursive valid rmse: 485.2940741\n",
      "\n",
      "Epoch: 7\n",
      "\ttrain loss: 0.0005440\ttrain_inversed_rmse: 394.4239197\n",
      "\trecursive valid rmse: 461.7611130\n",
      "\n",
      "Epoch: 8\n",
      "\ttrain loss: 0.0005106\ttrain_inversed_rmse: 382.1182556\n",
      "\trecursive valid rmse: 478.6382050\n",
      "\n",
      "Epoch: 9\n",
      "\ttrain loss: 0.0004781\ttrain_inversed_rmse: 369.7617493\n",
      "\trecursive valid rmse: 479.7197603\n",
      "\n",
      "Epoch: 10\n",
      "\ttrain loss: 0.0004647\ttrain_inversed_rmse: 364.5390930\n",
      "\trecursive valid rmse: 466.0962736\n",
      "\n",
      "Epoch: 11\n",
      "\ttrain loss: 0.0004370\ttrain_inversed_rmse: 353.5203247\n",
      "\trecursive valid rmse: 464.5427866\n",
      "\n",
      "Epoch: 12\n",
      "\ttrain loss: 0.0004322\ttrain_inversed_rmse: 351.5786743\n",
      "\trecursive valid rmse: 467.4795131\n",
      "\n",
      "Epoch: 13\n",
      "\ttrain loss: 0.0004194\ttrain_inversed_rmse: 346.3117676\n",
      "\trecursive valid rmse: 479.4057554\n",
      "\n",
      "Epoch: 14\n",
      "\ttrain loss: 0.0004002\ttrain_inversed_rmse: 338.3198547\n",
      "\trecursive valid rmse: 450.8589253\n",
      "\n",
      "Epoch: 15\n",
      "\ttrain loss: 0.0003955\ttrain_inversed_rmse: 336.3015442\n",
      "\trecursive valid rmse: 461.2903259\n",
      "\n",
      "Epoch: 16\n",
      "\ttrain loss: 0.0003734\ttrain_inversed_rmse: 326.7912598\n",
      "\trecursive valid rmse: 459.0663927\n",
      "\n",
      "Epoch: 17\n",
      "\ttrain loss: 0.0003758\ttrain_inversed_rmse: 327.8425598\n",
      "\trecursive valid rmse: 459.7251748\n",
      "\n",
      "Epoch: 18\n",
      "\ttrain loss: 0.0003691\ttrain_inversed_rmse: 324.8982544\n",
      "\trecursive valid rmse: 477.7899731\n",
      "\n",
      "Epoch: 19\n",
      "\ttrain loss: 0.0003635\ttrain_inversed_rmse: 322.4091797\n",
      "\trecursive valid rmse: 453.9827117\n",
      "\n",
      "Epoch: 20\n",
      "\ttrain loss: 0.0003533\ttrain_inversed_rmse: 317.8689575\n",
      "\trecursive valid rmse: 449.5968267\n",
      "\n",
      "Epoch: 21\n",
      "\ttrain loss: 0.0003535\ttrain_inversed_rmse: 317.9325562\n",
      "\trecursive valid rmse: 461.5203452\n",
      "\n",
      "Epoch: 22\n",
      "\ttrain loss: 0.0003451\ttrain_inversed_rmse: 314.1461792\n",
      "\trecursive valid rmse: 461.5877820\n",
      "\n",
      "Epoch: 23\n",
      "\ttrain loss: 0.0003419\ttrain_inversed_rmse: 312.6689148\n",
      "\trecursive valid rmse: 454.8964096\n",
      "\n",
      "Epoch: 24\n",
      "\ttrain loss: 0.0003332\ttrain_inversed_rmse: 308.6927185\n",
      "\trecursive valid rmse: 460.5580094\n",
      "\n",
      "Epoch: 25\n",
      "\ttrain loss: 0.0003333\ttrain_inversed_rmse: 308.7182007\n",
      "\trecursive valid rmse: 438.7965234\n",
      "\n",
      "Epoch: 26\n",
      "\ttrain loss: 0.0003347\ttrain_inversed_rmse: 309.3672180\n",
      "\trecursive valid rmse: 449.6204660\n",
      "\n",
      "Epoch: 27\n",
      "\ttrain loss: 0.0003287\ttrain_inversed_rmse: 306.5951843\n",
      "\trecursive valid rmse: 446.7145377\n",
      "\n",
      "Epoch: 28\n",
      "\ttrain loss: 0.0003271\ttrain_inversed_rmse: 305.8420715\n",
      "\trecursive valid rmse: 442.4222652\n",
      "\n",
      "Epoch: 29\n",
      "\ttrain loss: 0.0003225\ttrain_inversed_rmse: 303.6750488\n",
      "\trecursive valid rmse: 448.9758664\n",
      "\n",
      "Epoch: 30\n",
      "\ttrain loss: 0.0003157\ttrain_inversed_rmse: 300.4760132\n",
      "\trecursive valid rmse: 434.6700283\n",
      "\n",
      "Epoch: 31\n",
      "\ttrain loss: 0.0003145\ttrain_inversed_rmse: 299.8894043\n",
      "\trecursive valid rmse: 449.4999023\n",
      "\n",
      "Epoch: 32\n",
      "\ttrain loss: 0.0003120\ttrain_inversed_rmse: 298.7198181\n",
      "\trecursive valid rmse: 448.1518806\n",
      "\n",
      "Epoch: 33\n",
      "\ttrain loss: 0.0003079\ttrain_inversed_rmse: 296.7359924\n",
      "\trecursive valid rmse: 451.5142534\n",
      "\n",
      "Epoch: 34\n",
      "\ttrain loss: 0.0003112\ttrain_inversed_rmse: 298.3348389\n",
      "\trecursive valid rmse: 439.0398903\n",
      "\n",
      "Epoch: 35\n",
      "\ttrain loss: 0.0003051\ttrain_inversed_rmse: 295.3792114\n",
      "\trecursive valid rmse: 439.7018922\n",
      "\n",
      "Epoch: 36\n",
      "\ttrain loss: 0.0003062\ttrain_inversed_rmse: 295.9248352\n",
      "\trecursive valid rmse: 451.9260250\n",
      "\n",
      "Epoch: 37\n",
      "\ttrain loss: 0.0003034\ttrain_inversed_rmse: 294.5599060\n",
      "\trecursive valid rmse: 451.5023360\n",
      "\n",
      "Epoch: 38\n",
      "\ttrain loss: 0.0003040\ttrain_inversed_rmse: 294.8367004\n",
      "\trecursive valid rmse: 443.7499738\n",
      "\n",
      "Epoch: 39\n",
      "\ttrain loss: 0.0002971\ttrain_inversed_rmse: 291.4830933\n",
      "\trecursive valid rmse: 455.5483174\n",
      "\n",
      "Epoch: 40\n",
      "\ttrain loss: 0.0003004\ttrain_inversed_rmse: 293.0942993\n",
      "\trecursive valid rmse: 443.5054224\n",
      "\n",
      "\n",
      "Best epoch by recursive valid rmse: 40\n",
      "\ttrain loss: 0.0003157\ttrain_inversed_rmse: 300.4760132\n",
      "\trecursive valid rmse: 434.6700283\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_ds, valid_ds, CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fcbd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = set_model(CONFIGS, model_name='best_'+CONFIGS['model_name'])\n",
    "best_model.load_weights(f'{CONFIGS[\"model_path\"]}{CONFIGS[\"model_name\"]}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "679da351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.0001872\ttrain_rmse: 231.3749847\n",
      "valid_loss: 0.0005532\tvalid_rmse: 397.7495422\n",
      "test_loss: 0.0004342\ttest_rmse: 352.3868408\n",
      "\n",
      "recursive_valid_rmse: 434.670028\n",
      "recursive_test_rmse: 437.077567\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_rmse = best_model.evaluate(train_ds, verbose=0)\n",
    "valid_loss, valid_rmse = best_model.evaluate(valid_ds, verbose=0)\n",
    "test_loss, test_rmse = best_model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "recursive_valid_rmse = recursive_eval(best_model, valid_ds, 'valid', CONFIGS)\n",
    "recursive_test_rmse = recursive_eval(best_model, test_ds, 'test', CONFIGS)\n",
    "\n",
    "print(f'train_loss: {train_loss:.07f}\\ttrain_rmse: {train_rmse:.07f}')\n",
    "print(f'valid_loss: {valid_loss:.07f}\\tvalid_rmse: {valid_rmse:.07f}')\n",
    "print(f'test_loss: {test_loss:.07f}\\ttest_rmse: {test_rmse:.07f}')\n",
    "\n",
    "print(f'\\nrecursive_valid_rmse: {recursive_valid_rmse:.6f}\\nrecursive_test_rmse: {recursive_test_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e7c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
