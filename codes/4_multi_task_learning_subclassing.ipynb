{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71698c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import Loss\n",
    "from tensorflow.keras.metrics import Metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1b37d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = {\n",
    "    'data_path': '../data/',\n",
    "    'model_path': '../model/',\n",
    "    'model_name': 'multi_task_learning',\n",
    "    'model_type': 'cnn1d',\n",
    "    \n",
    "    'dtype': tf.float32,\n",
    "    \n",
    "    'valid_start_date_time': '2020-08-11 00',\n",
    "    'test_start_date_time': '2020-08-18 00',\n",
    "    \n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 5e-5,\n",
    "    'epochs': 100,\n",
    "    'es_patience': 10,\n",
    "    \n",
    "    'window_size': 7*24,\n",
    "    'shift': 1,\n",
    "    'target_length': 3,\n",
    "}\n",
    "\n",
    "CONFIGS['tensorboard_log_path'] = f'../logs/tensorboard/{CONFIGS[\"model_name\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef52c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin = pd.read_csv(CONFIGS['data_path']+'train.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f002b546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape: (122400, 10)\n"
     ]
    }
   ],
   "source": [
    "data = deepcopy(train_origin)\n",
    "\n",
    "data.columns = [\n",
    "    'num', 'date_time', 'target', 'temp', 'wind',\n",
    "    'humid', 'rain', 'sun', 'non_elec_eq', 'sunlight_eq'\n",
    "]\n",
    "\n",
    "data['num'] -= 1\n",
    "\n",
    "print(f'data.shape: {data.shape}')\n",
    "\n",
    "CONFIGS['n_buildings'] = len(data['num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42502fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_time_data(data):\n",
    "    \n",
    "    new_data = data.copy()\n",
    "\n",
    "    new_data['date_time'] = data['date_time'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H'))\n",
    "    \n",
    "    new_data['time_stamp'] = new_data['date_time'].apply(lambda x: x.timestamp())\n",
    "    \n",
    "    new_data['year'] = new_data['date_time'].apply(lambda x: x.year)\n",
    "    new_data['month'] = new_data['date_time'].apply(lambda x: x.month)\n",
    "    new_data['day'] = new_data['date_time'].apply(lambda x: x.day)\n",
    "    \n",
    "    new_data['hour'] = new_data['date_time'].apply(lambda x: x.hour)\n",
    "    new_data['cos_hour'] = np.cos(2*np.pi*(new_data['hour']/24))\n",
    "    new_data['sin_hour'] = np.sin(2*np.pi*(new_data['hour']/24))\n",
    "\n",
    "    new_data['weekday'] = new_data['date_time'].apply(lambda x: x.weekday())\n",
    "    new_data['cos_weekday'] = np.cos(2*np.pi*(new_data['weekday']/7))\n",
    "    new_data['sin_weekday'] = np.sin(2*np.pi*(new_data['weekday']/7))\n",
    "    \n",
    "    new_data['is_holiday'] = 0\n",
    "    new_data.loc[(new_data['weekday'] == 5) | (new_data['weekday'] == 6), 'is_holiday'] = 1\n",
    "    new_data.loc[(new_data['month'] == 8) & (new_data['day'] == 17), 'is_holiday'] = 1\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf4e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = mk_time_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61fdc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_building_info(data, data_for_calc, CONFIGS):\n",
    "        \n",
    "    new_data = data.copy()\n",
    "    new_data['range'] = 0\n",
    "    new_data['mean'] = 0\n",
    "    new_data['std'] = 0\n",
    "    new_data['holiday_gap'] = 0\n",
    "    new_data['day_gap'] = 0\n",
    "\n",
    "    for num in range(CONFIGS['n_buildings']):\n",
    "        building = data_for_calc.query(f'num == {num}')\n",
    "        \n",
    "        bt_range = building['target'].max()-building['target'].min()\n",
    "        bt_mean = building['target'].mean()\n",
    "        bt_std = building['target'].std()\n",
    "        bt_holiday_gap = abs(building.query('is_holiday == 0')['target'].mean() - building.query('is_holiday == 1')['target'].mean())\n",
    "        bt_day_gap = 0\n",
    "        for d in range(building.shape[0]//24):\n",
    "            tmp = building['target'][d*24:(d+1)*24]\n",
    "            bt_day_gap += (tmp.max()-tmp.min())/(building.shape[0]//24)\n",
    "            \n",
    "        new_data.loc[new_data['num']==num, 'range'] = bt_range\n",
    "        new_data.loc[new_data['num']==num, 'mean'] = bt_mean\n",
    "        new_data.loc[new_data['num']==num, 'std'] = bt_std\n",
    "        new_data.loc[new_data['num']==num, 'holiday_gap'] = bt_holiday_gap\n",
    "        new_data.loc[new_data['num']==num, 'day_gap'] = bt_day_gap\n",
    "        \n",
    "    new_data['mean_to_inverse'] = new_data['mean']\n",
    "    new_data['std_to_inverse'] = new_data['std']\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebaea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = mk_building_info(\n",
    "    new_data,\n",
    "    new_data[new_data['date_time']<CONFIGS['valid_start_date_time']],\n",
    "    CONFIGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8655ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_mean_std_dict(data, scaling_by_building_cols):\n",
    "    mean_std_dict = {}\n",
    "    for num in range(60):\n",
    "        building = data.query(f'num == {num}')\n",
    "        mean_std_dict[num] = {\n",
    "            col: {\n",
    "                'mean': building[col].mean(),\n",
    "                'std': building[col].std()\n",
    "            } for col in scaling_by_building_cols\n",
    "        }\n",
    "    return mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01506353",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_by_building_cols = [\n",
    "    'temp', 'wind', 'humid', 'rain', 'sun', 'time_stamp', 'target',\n",
    "]\n",
    "scaling_by_all_cols = ['range', 'mean', 'std', 'holiday_gap', 'day_gap']\n",
    "\n",
    "mean_std_dict = mk_mean_std_dict(\n",
    "    new_data[new_data['date_time'] < CONFIGS['valid_start_date_time']],\n",
    "    scaling_by_building_cols\n",
    ")\n",
    "CONFIGS['mean_std_dict'] = mean_std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d134a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaling(data, scaling_by_building_cols, scaling_by_all_cols, mean_std_dict=None):\n",
    "    if not mean_std_dict:\n",
    "        mean_std_dict = mk_mean_std_dict(data, scaling_by_building_cols)\n",
    "        \n",
    "    new_data = data.copy()\n",
    "    for num in range(60):\n",
    "        for col in scaling_by_building_cols:\n",
    "            new_data.loc[new_data['num']==num, col] -= mean_std_dict[num][col]['mean']\n",
    "            new_data.loc[new_data['num']==num, col] /= mean_std_dict[num][col]['std']\n",
    "    \n",
    "    for col in scaling_by_all_cols:\n",
    "        m = new_data.loc[:, col].mean()\n",
    "        s = new_data.loc[:, col].std()\n",
    "        new_data.loc[:, col] -= m\n",
    "        new_data.loc[:, col] /= s\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6674807",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = standard_scaling(new_data, scaling_by_building_cols, scaling_by_all_cols, mean_std_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b337cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_num_cols = ['num']\n",
    "building_info_cols = [\n",
    "    'range', 'mean', 'std', 'holiday_gap', 'day_gap',\n",
    "    'non_elec_eq', 'sunlight_eq',\n",
    "]\n",
    "target_time_info_cols = [\n",
    "    'temp', 'wind', 'humid', 'rain', 'sun', 'time_stamp',\n",
    "    'cos_hour', 'sin_hour', 'cos_weekday', 'sin_weekday',\n",
    "    'is_holiday',\n",
    "]\n",
    "time_series_cols = [\n",
    "    'temp', 'wind', 'humid', 'rain', 'sun', 'time_stamp',\n",
    "    'cos_hour', 'sin_hour', 'cos_weekday', 'sin_weekday',\n",
    "    'is_holiday', 'target',\n",
    "]\n",
    "target_cols = ['target']\n",
    "to_inverse_cols = ['mean_to_inverse', 'std_to_inverse']\n",
    "input_cols = list(set(\n",
    "    building_num_cols + building_info_cols + target_time_info_cols +\n",
    "    time_series_cols + target_cols + to_inverse_cols\n",
    "))\n",
    "\n",
    "\n",
    "CONFIGS['building_num_cols'] = building_num_cols\n",
    "CONFIGS['building_info_cols'] = building_info_cols\n",
    "CONFIGS['target_time_info_cols'] = target_time_info_cols\n",
    "CONFIGS['time_series_cols'] = time_series_cols\n",
    "CONFIGS['target_cols'] = target_cols\n",
    "CONFIGS['to_inverse_cols'] = to_inverse_cols\n",
    "CONFIGS['input_cols'] = input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dda65897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(data, crop_type, CONFIGS):\n",
    "    building_length = tf.shape(data)[0]\n",
    "    if crop_type == 'one_row':\n",
    "        h = CONFIGS['target_length']//2\n",
    "        croped = data[CONFIGS['window_size']+h:building_length-CONFIGS['target_length']+1+h]\n",
    "    elif crop_type == 'time_series_input':\n",
    "        croped = data[:-CONFIGS['target_length']]\n",
    "    elif crop_type == 'target':\n",
    "        croped = data[CONFIGS['window_size']:]\n",
    "    return croped\n",
    "\n",
    "\n",
    "def mk_window(data, size, shift):\n",
    "    ds = Dataset.from_tensor_slices(data)\n",
    "    ds = ds.window(\n",
    "        size=size, shift=shift, drop_remainder=True\n",
    "    ).flat_map(lambda x: x).batch(size)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def mk_time_series(data, building_length, crop_type, CONFIGS, dtype=None):\n",
    "    if not dtype:\n",
    "        dtype = CONFIGS['dtype']\n",
    "\n",
    "    ds = Dataset.from_tensor_slices(data).batch(building_length)\n",
    "    if crop_type == 'one_row':\n",
    "        ds = ds.map(lambda x: crop(x, crop_type, CONFIGS))\n",
    "        ds = ds.flat_map(lambda x: Dataset.from_tensor_slices(x))\n",
    "    elif crop_type == 'time_series_input':\n",
    "        ds = ds.map(lambda x: crop(x, crop_type, CONFIGS))\n",
    "        ds = ds.flat_map(\n",
    "            lambda x: mk_window(x, CONFIGS['window_size'], CONFIGS['shift']))\n",
    "    elif crop_type == 'target':\n",
    "        ds = ds.map(lambda x: crop(x, crop_type, CONFIGS))\n",
    "        ds = ds.flat_map(\n",
    "            lambda x: mk_window(x, CONFIGS['target_length'], CONFIGS['shift']))\n",
    "    ds.map(lambda x: tf.cast(x, dtype))\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def mk_dataset(data, CONFIGS, shuffle=False):\n",
    "\n",
    "    data = data[CONFIGS['input_cols']]\n",
    "    building_length = data.shape[0]//60\n",
    "\n",
    "    building_num = data[CONFIGS['building_num_cols']]\n",
    "    building_info = data[CONFIGS['building_info_cols']]\n",
    "    target_time_info = data[CONFIGS['target_time_info_cols']]\n",
    "    time_series = data[CONFIGS['time_series_cols']]\n",
    "    to_inverse = data[CONFIGS['to_inverse_cols']]\n",
    "    target = data[CONFIGS['target_cols']]\n",
    "\n",
    "    building_num_ds = mk_time_series(building_num, building_length, 'one_row', CONFIGS, tf.int16)\n",
    "    building_info_ds = mk_time_series(building_info, building_length, 'one_row', CONFIGS)\n",
    "    target_time_info_ds = mk_time_series(target_time_info, building_length, 'one_row', CONFIGS)\n",
    "    time_series_ds = mk_time_series(time_series, building_length, 'time_series_input', CONFIGS)\n",
    "    target_ds = mk_time_series(target, building_length, 'target', CONFIGS)\n",
    "    to_inverse_ds = mk_time_series(to_inverse, building_length, 'one_row', CONFIGS)\n",
    "    \n",
    "    # zip\n",
    "    ds = Dataset.zip((\n",
    "        (\n",
    "            building_num_ds,\n",
    "            building_info_ds,\n",
    "            target_time_info_ds,\n",
    "            time_series_ds,\n",
    "            to_inverse_ds\n",
    "        ),\n",
    "        target_ds\n",
    "    ))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(512)\n",
    "    ds = ds.batch(CONFIGS['batch_size']).cache().prefetch(2)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0107708e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:11:01.345823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:01.681470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:01.682134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:01.693541: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-14 15:11:01.696919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:01.697529: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:01.698106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:04.349524: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:04.350199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:04.350718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-14 15:11:04.354074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6080 MB memory:  -> device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:07:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "str_to_dt = lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H')\n",
    "hour_to_td = lambda x: datetime.timedelta(hours=x)\n",
    "\n",
    "train = new_data.loc[\n",
    "    new_data['date_time'] < \\\n",
    "        str_to_dt(CONFIGS['valid_start_date_time']),\n",
    "    :\n",
    "]\n",
    "valid = new_data.loc[\n",
    "    (new_data['date_time'] >= \\\n",
    "        str_to_dt(CONFIGS['valid_start_date_time'])-hour_to_td(CONFIGS['window_size']))&\\\n",
    "    (new_data['date_time'] < \\\n",
    "         str_to_dt(CONFIGS['test_start_date_time'])),\n",
    "    :\n",
    "]\n",
    "test = new_data.loc[\n",
    "    new_data['date_time'] >= \\\n",
    "        str_to_dt(CONFIGS['test_start_date_time'])-hour_to_td(CONFIGS['window_size']),\n",
    "    :\n",
    "]\n",
    "\n",
    "train_ds = mk_dataset(train, CONFIGS, shuffle=True)\n",
    "valid_ds = mk_dataset(valid, CONFIGS)\n",
    "test_ds = mk_dataset(test, CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a71c8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMSE(Loss):\n",
    "    \n",
    "    def __init__(self, target_max, name=\"custom_mse\"):\n",
    "        super(CustomMSE, self).__init__(name=name)\n",
    "        self.target_max = target_max\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        y_true = tf.squeeze(y_true)\n",
    "        mean = tf.reshape(y_pred[:, -2], (-1, 1))\n",
    "        std = tf.reshape(y_pred[:, -1], (-1, 1))\n",
    "        y_pred = y_pred[:, :-2]\n",
    "\n",
    "        y_true_inversed = y_true*std+mean\n",
    "        y_pred_inversed = y_pred*std+mean\n",
    "        \n",
    "        y_true_inversed_scaled = y_true_inversed/self.target_max\n",
    "        y_pred_inversed_scaled = y_pred_inversed/self.target_max\n",
    "\n",
    "        mse = tf.reduce_mean((y_true_inversed_scaled-y_pred_inversed_scaled)**2)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "875ba5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InversedRMSE(Metric):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name=\"inversed_rmse\", **kwargs):\n",
    "        super(InversedRMSE, self).__init__(name=name, **kwargs)\n",
    "        self.inversed_mse = self.add_weight(name='inversed_mse', initializer='zeros')\n",
    "        self.count = self.add_weight(name='count', initializer='zeros')\n",
    "        self.CONFIGS = CONFIGS\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, (-1, CONFIGS['target_length']))\n",
    "        mean = tf.reshape(y_pred[:, -2], (-1, 1))\n",
    "        std = tf.reshape(y_pred[:, -1], (-1, 1))\n",
    "        y_pred = y_pred[:, :-2]\n",
    "\n",
    "        y_true_inversed = y_true*std+mean\n",
    "        y_pred_inversed = y_pred*std+mean\n",
    "\n",
    "        error = tf.reduce_sum(tf.math.squared_difference(y_true_inversed, y_pred_inversed))\n",
    "        \n",
    "        self.inversed_mse.assign_add(error)\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), CONFIGS['dtype']))\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(tf.math.divide_no_nan(self.inversed_mse, self.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51a38be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingNumLayer(Layer):\n",
    "\n",
    "    def __init__(self, CONFIGS, name='building_num_layer', **kwargs):\n",
    "        super(BuildingNumLayer, self).__init__(name=name, **kwargs)\n",
    "        self.building_num_emb = Embedding(\n",
    "            input_dim=CONFIGS['n_buildings'],\n",
    "            output_dim=CONFIGS['embedding_dim']\n",
    "        )\n",
    "        self.bn_outputs = Reshape(target_shape=(CONFIGS['embedding_dim'],))\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(BuildingNumLayer, self).get_config().copy()\n",
    "        config.update({\n",
    "            'building_num_emb': self.building_num_emb,\n",
    "            'bn_outputs': self.bn_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.building_num_emb(inputs)\n",
    "        outputs = self.bn_outputs(x)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class BuildingInfoLayer(Layer):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name='building_info_layer', **kwargs):\n",
    "        super(BuildingInfoLayer, self).__init__(name=name, **kwargs)\n",
    "        self.bi_dense_0 = Dense(16, activation='relu')\n",
    "        self.dropout_0 = Dropout(0.3)\n",
    "        self.bi_outputs = Dense(32, activation='relu')\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(BuildingInfoLayer, self).get_config().copy()\n",
    "        config.update({\n",
    "            'bi_dense_0': self.bi_dense_0,\n",
    "            'dropout_0': self.dropout_0,\n",
    "            'bi_outputs': self.bi_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.bi_dense_0(inputs)\n",
    "        x = self.dropout_0(x)\n",
    "        outputs = self.bi_outputs(x)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class TargetTimeInfoLayer(Layer):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name='target_time_info_layer', **kwargs):\n",
    "        super(TargetTimeInfoLayer, self).__init__(name=name, **kwargs)\n",
    "        self.tti_dense_0 = Dense(16, activation='relu')\n",
    "        self.dropout_0 = Dropout(0.3)\n",
    "        self.tti_outputs = Dense(32, activation='relu')\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(TargetTimeInfoLayer, self).get_config().copy()\n",
    "        config.update({\n",
    "            'tti_dense_0': self.tti_dense_0,\n",
    "            'dropout_0': self.dropout_0,\n",
    "            'tti_outputs': self.tti_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.tti_dense_0(inputs)\n",
    "        x = self.dropout_0(x)\n",
    "        outputs = self.tti_outputs(x)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "class TimeSeriesLayer(Layer):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name='time_series_layer', **kwargs):\n",
    "        super(TimeSeriesLayer, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        if CONFIGS['model_type'] == 'flatten':\n",
    "            pass\n",
    "        elif CONFIGS['model_type'] == 'cnn1d':\n",
    "            self.conv1d_0 = Conv1D(16, 3, 2, activation='relu')\n",
    "            self.pool1d_0 = MaxPool1D(2)\n",
    "            self.conv1d_1 = Conv1D(32, 3, 2, activation='relu')\n",
    "            self.pool1d_1 = MaxPool1D(2)\n",
    "        elif CONFIGS['model_type'] == 'cnn2d':\n",
    "            self.conv2d_reshape = Reshape(target_shape=(\n",
    "                CONFIGS['window_size'], len(CONFIGS['time_series_cols']), 1\n",
    "            ))\n",
    "            self.conv2d_0 = Conv2D(8, (3, 1), strides=(2, 1), activation='relu')\n",
    "            self.pool2d_0 = MaxPool2D((2, 1))\n",
    "            self.conv2d_1 = Conv2D(16, (3, 1), strides=(2, 1), activation='relu')\n",
    "            self.pool2d_1 = MaxPool2D((2, 1))\n",
    "        elif CONFIGS['model_type'] == 'lstm':\n",
    "            self.lstm_0 = LSTM(16, return_sequences=True, activation='relu')\n",
    "            self.lstm_1 = LSTM(32, activation='relu')\n",
    "        elif CONFIGS['model_type'] == 'bilstm':\n",
    "            self.bilstm_0 = Bidirectional(LSTM(16, return_sequences=True, activation='relu'))\n",
    "            self.bilstm_1 = Bidirectional(LSTM(32, activation='relu'))\n",
    "        self.time_series_outputs = Flatten()\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super(TimeSeriesLayer, self).get_config().copy()\n",
    "        if CONFIGS['model_type'] == 'flatten':\n",
    "            pass\n",
    "        elif CONFIGS['model_type'] == 'cnn1d':\n",
    "            config.update({\n",
    "                'conv1d_0': self.conv1d_0,\n",
    "                'pool1d_0': self.pool1d_0,\n",
    "                'conv1d_1': self.conv1d_1,\n",
    "                'pool1d_1': self.pool1d_1,\n",
    "            })\n",
    "        elif CONFIGS['model_type'] == 'cnn2d':\n",
    "            config.update({\n",
    "                'conv2d_reshape': self.conv2d_reshape,\n",
    "                'conv2d_0': self.conv2d_0,\n",
    "                'pool2d_0': self.pool2d_0,\n",
    "                'conv2d_1': self.conv2d_1,\n",
    "                'pool2d_1': self.pool2d_1,\n",
    "            })\n",
    "        elif CONFIGS['model_type'] == 'lstm':\n",
    "            config.update({\n",
    "                'lstm_0': self.lstm_0,\n",
    "                'lstm_1': self.lstm_1,\n",
    "            })\n",
    "        elif CONFIGS['model_type'] == 'bilstm':\n",
    "            config.update({\n",
    "                'bilstm_0': self.bilstm_0,\n",
    "                'bilstm_1': self.bilstm_1,\n",
    "            })\n",
    "        config.update({\n",
    "            'time_series_outputs': self.time_series_outputs,\n",
    "        })\n",
    "        return config\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        if CONFIGS['model_type'] == 'flatten':\n",
    "            x = inputs\n",
    "        elif CONFIGS['model_type'] == 'cnn1d':\n",
    "            x = self.conv1d_0(inputs)\n",
    "            x = self.pool1d_0(x)\n",
    "            x = self.conv1d_1(x)\n",
    "            x = self.pool1d_1(x)\n",
    "        elif CONFIGS['model_type'] == 'cnn2d':\n",
    "            x = self.conv2d_reshape(x)\n",
    "            x = self.conv2d_0(x)\n",
    "            x = self.pool2d_0(x)\n",
    "            x = self.conv2d_1(x)\n",
    "            x = self.pool2d_1(x)\n",
    "        elif CONFIGS['model_type'] == 'lstm':\n",
    "            x = self.lstm_0(x)\n",
    "            x = self.lstm_1(x)\n",
    "        elif CONFIGS['model_type'] == 'bilstm':\n",
    "            x = self.bilstm_0(x)\n",
    "            x = self.bilstm_1(x)\n",
    "        outputs = self.time_series_outputs(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1ca8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElectricityModel(Model):\n",
    "    \n",
    "    def __init__(self, CONFIGS, name=None, **kwargs):\n",
    "        if not name:\n",
    "            name = CONFIGS['model_name']\n",
    "            \n",
    "        super(ElectricityModel, self).__init__(name=name, **kwargs)\n",
    "        \n",
    "        self.building_num_layer = BuildingNumLayer(CONFIGS)\n",
    "        self.building_info_layer = BuildingInfoLayer(CONFIGS)\n",
    "        self.target_time_info_layer = TargetTimeInfoLayer(CONFIGS)\n",
    "        self.time_series_layer = TimeSeriesLayer(CONFIGS)\n",
    "        self.concat_vars = Concatenate(name='concat_vars')\n",
    "        self.dense_block = Sequential([\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(CONFIGS['target_length']),\n",
    "        ], name='dense_block')\n",
    "        self.concat_to_inverse = Concatenate(name='concat_to_inverse')\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        bn_inputs, bi_inputs, tti_inputs, ts_inputs, ti_inputs = inputs\n",
    "        bn_outputs = self.building_num_layer(bn_inputs)\n",
    "        bi_outputs = self.building_info_layer(bi_inputs, training=training)\n",
    "        tti_outputs = self.target_time_info_layer(tti_inputs, training=training)\n",
    "        time_series_outputs = self.time_series_layer(ts_inputs)\n",
    "        concat_vars = self.concat_vars([bn_outputs, bi_outputs, tti_outputs, time_series_outputs])\n",
    "        dense_block_outputs = self.dense_block(concat_vars)\n",
    "        outputs = self.concat_to_inverse([dense_block_outputs, ti_inputs])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e5497b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS['target_max'] = \\\n",
    "    data[data['date_time']<CONFIGS['valid_start_date_time']]['target'].max()\n",
    "CONFIGS['embedding_dim'] = 10\n",
    "\n",
    "\n",
    "bn_inputs = Input(batch_shape=(None, 1), name='building_num_inputs')\n",
    "bi_inputs = Input(\n",
    "    batch_shape=(None, len(CONFIGS['building_info_cols'])),\n",
    "    name='building_info_inputs'\n",
    ")\n",
    "tti_inputs = target_time_info_inputs = Input(\n",
    "    batch_shape=(None, len(CONFIGS['target_time_info_cols'])),\n",
    "    name='target_time_info_inputs'\n",
    ")\n",
    "ts_inputs = Input(batch_shape=(\n",
    "    None, CONFIGS['window_size'], len(CONFIGS['time_series_cols'])\n",
    "), name='time_series_inputs')\n",
    "ti_inputs = Input(batch_shape=(None, len(CONFIGS['to_inverse_cols'])), name='to_inverse_inputs')\n",
    "inputs = [bn_inputs, bi_inputs, tti_inputs, ts_inputs, ti_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c00604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_task_learning\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                                         Output Shape                                    Param #           \n",
      "========================================================================================================================\n",
      " building_num_layer (BuildingNumLayer)                multiple                                        600               \n",
      "                                                                                                                        \n",
      " building_info_layer (BuildingInfoLayer)              multiple                                        672               \n",
      "                                                                                                                        \n",
      " target_time_info_layer (TargetTimeInfoLayer)         multiple                                        736               \n",
      "                                                                                                                        \n",
      " time_series_layer (TimeSeriesLayer)                  multiple                                        2160              \n",
      "                                                                                                                        \n",
      " concat_vars (Concatenate)                            multiple                                        0                 \n",
      "                                                                                                                        \n",
      " dense_block (Sequential)                             (None, 3)                                       27459             \n",
      "                                                                                                                        \n",
      " concat_to_inverse (Concatenate)                      multiple                                        0                 \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 31,627\n",
      "Trainable params: 31,627\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ElectricityModel(CONFIGS)\n",
    "model.build(list(map(lambda x: list(x.shape), inputs)))\n",
    "\n",
    "model.summary(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf1307c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mse = CustomMSE(CONFIGS['target_max'])\n",
    "inversed_rmse = InversedRMSE(CONFIGS)\n",
    "optimizer = Adam(learning_rate=CONFIGS['learning_rate'])\n",
    "model.compile(\n",
    "    loss = custom_mse,\n",
    "    optimizer = optimizer,\n",
    "    metrics = [inversed_rmse],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a889564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_ds, valid_ds, CONFIGS):\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        patience=CONFIGS['es_patience']\n",
    "    )\n",
    "    save_best_only = ModelCheckpoint(\n",
    "        filepath = f'{CONFIGS[\"model_path\"]}{CONFIGS[\"model_name\"]}.h5',\n",
    "        monitor = 'val_loss',\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True\n",
    "    )\n",
    "    tensorboard_callback = TensorBoard(\n",
    "        log_dir = CONFIGS['tensorboard_log_path']\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        batch_size = CONFIGS['batch_size'],\n",
    "        epochs = CONFIGS['epochs'],\n",
    "        validation_data = valid_ds,\n",
    "        callbacks = [\n",
    "            early_stop,\n",
    "            save_best_only,\n",
    "            tensorboard_callback,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdb115f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 15:11:17.548072: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439/1439 [==============================] - 36s 9ms/step - loss: 0.0026 - inversed_rmse: 867.4961 - val_loss: 0.0028 - val_inversed_rmse: 902.0741\n",
      "Epoch 2/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 0.0018 - inversed_rmse: 718.0771 - val_loss: 0.0020 - val_inversed_rmse: 756.4524\n",
      "Epoch 3/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 0.0015 - inversed_rmse: 645.3754 - val_loss: 0.0016 - val_inversed_rmse: 682.5682\n",
      "Epoch 4/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 0.0013 - inversed_rmse: 599.0232 - val_loss: 0.0014 - val_inversed_rmse: 630.9252\n",
      "Epoch 5/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 0.0011 - inversed_rmse: 565.9589 - val_loss: 0.0012 - val_inversed_rmse: 591.1918\n",
      "Epoch 6/100\n",
      "1439/1439 [==============================] - 7s 5ms/step - loss: 0.0010 - inversed_rmse: 535.0428 - val_loss: 0.0011 - val_inversed_rmse: 561.5344\n",
      "Epoch 7/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 8.9165e-04 - inversed_rmse: 504.9677 - val_loss: 0.0010 - val_inversed_rmse: 539.4108\n",
      "Epoch 8/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 8.1872e-04 - inversed_rmse: 483.8731 - val_loss: 9.4794e-04 - val_inversed_rmse: 520.6621\n",
      "Epoch 9/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 7.5441e-04 - inversed_rmse: 464.4821 - val_loss: 8.9539e-04 - val_inversed_rmse: 506.0235\n",
      "Epoch 10/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 7.0350e-04 - inversed_rmse: 448.5364 - val_loss: 8.4044e-04 - val_inversed_rmse: 490.2516\n",
      "Epoch 11/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 6.6793e-04 - inversed_rmse: 437.0506 - val_loss: 8.1722e-04 - val_inversed_rmse: 483.4302\n",
      "Epoch 12/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 6.3892e-04 - inversed_rmse: 427.4522 - val_loss: 7.9110e-04 - val_inversed_rmse: 475.6416\n",
      "Epoch 13/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 6.0613e-04 - inversed_rmse: 416.3393 - val_loss: 7.7906e-04 - val_inversed_rmse: 472.0097\n",
      "Epoch 14/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 5.7920e-04 - inversed_rmse: 406.9845 - val_loss: 7.5764e-04 - val_inversed_rmse: 465.4754\n",
      "Epoch 15/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 5.7103e-04 - inversed_rmse: 404.1045 - val_loss: 7.4207e-04 - val_inversed_rmse: 460.6683\n",
      "Epoch 16/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 5.4765e-04 - inversed_rmse: 395.7452 - val_loss: 7.3550e-04 - val_inversed_rmse: 458.6240\n",
      "Epoch 17/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 5.3006e-04 - inversed_rmse: 389.3387 - val_loss: 7.3099e-04 - val_inversed_rmse: 457.2152\n",
      "Epoch 18/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 5.0522e-04 - inversed_rmse: 380.1077 - val_loss: 7.3118e-04 - val_inversed_rmse: 457.2754\n",
      "Epoch 19/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 5.0684e-04 - inversed_rmse: 380.7160 - val_loss: 7.1109e-04 - val_inversed_rmse: 450.9499\n",
      "Epoch 20/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.8574e-04 - inversed_rmse: 372.7049 - val_loss: 7.0749e-04 - val_inversed_rmse: 449.8051\n",
      "Epoch 21/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.7757e-04 - inversed_rmse: 369.5592 - val_loss: 7.1992e-04 - val_inversed_rmse: 453.7390\n",
      "Epoch 22/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.6865e-04 - inversed_rmse: 366.0924 - val_loss: 6.8978e-04 - val_inversed_rmse: 444.1398\n",
      "Epoch 23/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.5831e-04 - inversed_rmse: 362.0313 - val_loss: 6.9195e-04 - val_inversed_rmse: 444.8385\n",
      "Epoch 24/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.5186e-04 - inversed_rmse: 359.4755 - val_loss: 6.8840e-04 - val_inversed_rmse: 443.6964\n",
      "Epoch 25/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.4295e-04 - inversed_rmse: 355.9116 - val_loss: 6.7648e-04 - val_inversed_rmse: 439.8366\n",
      "Epoch 26/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.2419e-04 - inversed_rmse: 348.2957 - val_loss: 6.7397e-04 - val_inversed_rmse: 439.0216\n",
      "Epoch 27/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.2359e-04 - inversed_rmse: 348.0472 - val_loss: 6.7353e-04 - val_inversed_rmse: 438.8764\n",
      "Epoch 28/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.2148e-04 - inversed_rmse: 347.1786 - val_loss: 6.5802e-04 - val_inversed_rmse: 433.7966\n",
      "Epoch 29/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.0910e-04 - inversed_rmse: 342.0414 - val_loss: 6.5256e-04 - val_inversed_rmse: 431.9919\n",
      "Epoch 30/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 4.0289e-04 - inversed_rmse: 339.4356 - val_loss: 6.4880e-04 - val_inversed_rmse: 430.7457\n",
      "Epoch 31/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.9409e-04 - inversed_rmse: 335.7111 - val_loss: 6.4050e-04 - val_inversed_rmse: 427.9809\n",
      "Epoch 32/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.8747e-04 - inversed_rmse: 332.8787 - val_loss: 6.3643e-04 - val_inversed_rmse: 426.6190\n",
      "Epoch 33/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.9416e-04 - inversed_rmse: 335.7402 - val_loss: 6.1620e-04 - val_inversed_rmse: 419.7841\n",
      "Epoch 34/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.8245e-04 - inversed_rmse: 330.7148 - val_loss: 6.2982e-04 - val_inversed_rmse: 424.3989\n",
      "Epoch 35/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.7403e-04 - inversed_rmse: 327.0537 - val_loss: 6.2073e-04 - val_inversed_rmse: 421.3240\n",
      "Epoch 36/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.6786e-04 - inversed_rmse: 324.3446 - val_loss: 6.2582e-04 - val_inversed_rmse: 423.0471\n",
      "Epoch 37/100\n",
      "1439/1439 [==============================] - 7s 5ms/step - loss: 3.6766e-04 - inversed_rmse: 324.2582 - val_loss: 6.1705e-04 - val_inversed_rmse: 420.0753\n",
      "Epoch 38/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.6540e-04 - inversed_rmse: 323.2586 - val_loss: 6.0625e-04 - val_inversed_rmse: 416.3830\n",
      "Epoch 39/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.5838e-04 - inversed_rmse: 320.1386 - val_loss: 5.9592e-04 - val_inversed_rmse: 412.8205\n",
      "Epoch 40/100\n",
      "1439/1439 [==============================] - 7s 5ms/step - loss: 3.6088e-04 - inversed_rmse: 321.2540 - val_loss: 6.0975e-04 - val_inversed_rmse: 417.5812\n",
      "Epoch 41/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.5419e-04 - inversed_rmse: 318.2589 - val_loss: 6.0055e-04 - val_inversed_rmse: 414.4192\n",
      "Epoch 42/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.4925e-04 - inversed_rmse: 316.0347 - val_loss: 5.9581e-04 - val_inversed_rmse: 412.7800\n",
      "Epoch 43/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.4612e-04 - inversed_rmse: 314.6168 - val_loss: 5.9127e-04 - val_inversed_rmse: 411.2048\n",
      "Epoch 44/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.4532e-04 - inversed_rmse: 314.2508 - val_loss: 5.9649e-04 - val_inversed_rmse: 413.0159\n",
      "Epoch 45/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.3978e-04 - inversed_rmse: 311.7177 - val_loss: 5.9766e-04 - val_inversed_rmse: 413.4206\n",
      "Epoch 46/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.3440e-04 - inversed_rmse: 309.2416 - val_loss: 5.8707e-04 - val_inversed_rmse: 409.7435\n",
      "Epoch 47/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.3712e-04 - inversed_rmse: 310.4972 - val_loss: 5.7689e-04 - val_inversed_rmse: 406.1744\n",
      "Epoch 48/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.3713e-04 - inversed_rmse: 310.5041 - val_loss: 5.7312e-04 - val_inversed_rmse: 404.8445\n",
      "Epoch 49/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.2548e-04 - inversed_rmse: 305.0884 - val_loss: 5.7200e-04 - val_inversed_rmse: 404.4497\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.2760e-04 - inversed_rmse: 306.0796 - val_loss: 5.6516e-04 - val_inversed_rmse: 402.0233\n",
      "Epoch 51/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.2655e-04 - inversed_rmse: 305.5893 - val_loss: 5.6208e-04 - val_inversed_rmse: 400.9260\n",
      "Epoch 52/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.2132e-04 - inversed_rmse: 303.1315 - val_loss: 5.7836e-04 - val_inversed_rmse: 406.6922\n",
      "Epoch 53/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1977e-04 - inversed_rmse: 302.4034 - val_loss: 5.7310e-04 - val_inversed_rmse: 404.8380\n",
      "Epoch 54/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1965e-04 - inversed_rmse: 302.3448 - val_loss: 5.6787e-04 - val_inversed_rmse: 402.9846\n",
      "Epoch 55/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1637e-04 - inversed_rmse: 300.7919 - val_loss: 5.6181e-04 - val_inversed_rmse: 400.8307\n",
      "Epoch 56/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1789e-04 - inversed_rmse: 301.5122 - val_loss: 5.6573e-04 - val_inversed_rmse: 402.2249\n",
      "Epoch 57/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1605e-04 - inversed_rmse: 300.6375 - val_loss: 5.5812e-04 - val_inversed_rmse: 399.5116\n",
      "Epoch 58/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1416e-04 - inversed_rmse: 299.7366 - val_loss: 5.5378e-04 - val_inversed_rmse: 397.9557\n",
      "Epoch 59/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1104e-04 - inversed_rmse: 298.2440 - val_loss: 5.6688e-04 - val_inversed_rmse: 402.6360\n",
      "Epoch 60/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.1244e-04 - inversed_rmse: 298.9167 - val_loss: 5.5372e-04 - val_inversed_rmse: 397.9325\n",
      "Epoch 61/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.0753e-04 - inversed_rmse: 296.5565 - val_loss: 5.5917e-04 - val_inversed_rmse: 399.8862\n",
      "Epoch 62/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.0489e-04 - inversed_rmse: 295.2838 - val_loss: 5.5310e-04 - val_inversed_rmse: 397.7090\n",
      "Epoch 63/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.0417e-04 - inversed_rmse: 294.9351 - val_loss: 5.6312e-04 - val_inversed_rmse: 401.2959\n",
      "Epoch 64/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.0160e-04 - inversed_rmse: 293.6853 - val_loss: 5.5979e-04 - val_inversed_rmse: 400.1084\n",
      "Epoch 65/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.0377e-04 - inversed_rmse: 294.7415 - val_loss: 5.5017e-04 - val_inversed_rmse: 396.6567\n",
      "Epoch 66/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 3.0355e-04 - inversed_rmse: 294.6300 - val_loss: 5.4033e-04 - val_inversed_rmse: 393.0909\n",
      "Epoch 67/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9973e-04 - inversed_rmse: 292.7714 - val_loss: 5.4773e-04 - val_inversed_rmse: 395.7765\n",
      "Epoch 68/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9779e-04 - inversed_rmse: 291.8224 - val_loss: 5.4926e-04 - val_inversed_rmse: 396.3282\n",
      "Epoch 69/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9904e-04 - inversed_rmse: 292.4366 - val_loss: 5.5304e-04 - val_inversed_rmse: 397.6892\n",
      "Epoch 70/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9692e-04 - inversed_rmse: 291.3950 - val_loss: 5.4010e-04 - val_inversed_rmse: 393.0077\n",
      "Epoch 71/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9486e-04 - inversed_rmse: 290.3853 - val_loss: 5.3514e-04 - val_inversed_rmse: 391.1984\n",
      "Epoch 72/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9171e-04 - inversed_rmse: 288.8293 - val_loss: 5.4678e-04 - val_inversed_rmse: 395.4324\n",
      "Epoch 73/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9840e-04 - inversed_rmse: 292.1205 - val_loss: 5.6401e-04 - val_inversed_rmse: 401.6149\n",
      "Epoch 74/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9346e-04 - inversed_rmse: 289.6952 - val_loss: 5.4412e-04 - val_inversed_rmse: 394.4672\n",
      "Epoch 75/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9347e-04 - inversed_rmse: 289.6992 - val_loss: 5.4635e-04 - val_inversed_rmse: 395.2779\n",
      "Epoch 76/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9198e-04 - inversed_rmse: 288.9634 - val_loss: 5.5448e-04 - val_inversed_rmse: 398.2050\n",
      "Epoch 77/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9308e-04 - inversed_rmse: 289.5073 - val_loss: 5.4242e-04 - val_inversed_rmse: 393.8509\n",
      "Epoch 78/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.8781e-04 - inversed_rmse: 286.8919 - val_loss: 5.4323e-04 - val_inversed_rmse: 394.1474\n",
      "Epoch 79/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.8726e-04 - inversed_rmse: 286.6182 - val_loss: 5.4229e-04 - val_inversed_rmse: 393.8032\n",
      "Epoch 80/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.9140e-04 - inversed_rmse: 288.6750 - val_loss: 5.4330e-04 - val_inversed_rmse: 394.1718\n",
      "Epoch 81/100\n",
      "1439/1439 [==============================] - 6s 4ms/step - loss: 2.8766e-04 - inversed_rmse: 286.8162 - val_loss: 5.5101e-04 - val_inversed_rmse: 396.9591\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, train_ds, valid_ds, CONFIGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fcbd203",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = ElectricityModel(CONFIGS, name='best_'+CONFIGS['model_name'])\n",
    "best_model.compile(\n",
    "    loss = custom_mse,\n",
    "    optimizer = optimizer,\n",
    "    metrics = [inversed_rmse],\n",
    ")\n",
    "_ = best_model(inputs)\n",
    "best_model.load_weights(f'{CONFIGS[\"model_path\"]}{CONFIGS[\"model_name\"]}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "679da351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.000155\ttrain_rmse: 226.850250\n",
      "valid_loss: 0.000535\tvalid_rmse: 391.198395\n",
      "test_loss: 0.000410\ttest_rmse: 342.603912\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_rmse = best_model.evaluate(train_ds, verbose=0)\n",
    "valid_loss, valid_rmse = best_model.evaluate(valid_ds, verbose=0)\n",
    "test_loss, test_rmse = best_model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "print(f'train_loss: {train_loss:.6f}\\ttrain_rmse: {train_rmse:.6f}')\n",
    "print(f'valid_loss: {valid_loss:.6f}\\tvalid_rmse: {valid_rmse:.6f}')\n",
    "print(f'test_loss: {test_loss:.6f}\\ttest_rmse: {test_rmse:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb35e5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
